{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMLnoHjtNqYqIARIEF7jxtK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/s183796/Group5_repos/blob/main/3D_unet_test_pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u5K-M-WHe_zR",
        "outputId": "6cbecc65-0d44-4799-841e-b94e3436254f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "loaded packages\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Image, display, clear_output\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models\n",
        "from torch.nn.functional import relu\n",
        "from torch.nn.functional import softmax\n",
        "import PIL.Image\n",
        "import os\n",
        "import torchvision\n",
        "import cv2\n",
        "\n",
        "from torchvision import transforms\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from torch.utils.data import DataLoader, Dataset, Subset\n",
        "\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms.functional as TF\n",
        "import glob\n",
        "import random\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "print('loaded packages')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torchio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9MkvoH-Ff3VO",
        "outputId": "ac9069c7-3f94-4b9b-ae29-7f31a56007ac"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchio\n",
            "  Downloading torchio-0.19.3-py2.py3-none-any.whl (172 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.0/173.0 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Deprecated (from torchio)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting SimpleITK!=2.0.*,!=2.1.1.1 (from torchio)\n",
            "  Downloading SimpleITK-2.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (52.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.7/52.7 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: humanize in /usr/local/lib/python3.10/dist-packages (from torchio) (4.7.0)\n",
            "Requirement already satisfied: nibabel in /usr/local/lib/python3.10/dist-packages (from torchio) (4.0.2)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.10/dist-packages (from torchio) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torchio) (1.11.4)\n",
            "Requirement already satisfied: torch>=1.1 in /usr/local/lib/python3.10/dist-packages (from torchio) (2.1.0+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchio) (4.66.1)\n",
            "Requirement already satisfied: typer[all] in /usr/local/lib/python3.10/dist-packages (from torchio) (0.9.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.1->torchio) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.1->torchio) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.1->torchio) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.1->torchio) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.1->torchio) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.1->torchio) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.1->torchio) (2.1.0)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from Deprecated->torchio) (1.14.1)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from nibabel->torchio) (23.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nibabel->torchio) (67.7.2)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer[all]->torchio) (8.1.7)\n",
            "Collecting colorama<0.5.0,>=0.4.3 (from typer[all]->torchio)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Collecting shellingham<2.0.0,>=1.3.0 (from typer[all]->torchio)\n",
            "  Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: rich<14.0.0,>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer[all]->torchio) (13.7.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=10.11.0->typer[all]->torchio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=10.11.0->typer[all]->torchio) (2.16.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.1->torchio) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.1->torchio) (1.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=10.11.0->typer[all]->torchio) (0.1.2)\n",
            "Installing collected packages: SimpleITK, shellingham, Deprecated, colorama, torchio\n",
            "Successfully installed Deprecated-1.2.14 SimpleITK-2.3.1 colorama-0.4.6 shellingham-1.5.4 torchio-0.19.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Source: https://towardsdatascience.com/cook-your-first-u-net-in-pytorch-b3297a844cf3, visited the 16th of November 2023\n",
        "# Modifications have been made to the original code with changing the input and output sizes\n",
        "\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, n_class):\n",
        "        super().__init__()\n",
        "\n",
        "        # input: 1x128x128\n",
        "        self.e11 = nn.Conv3d(1, 64, kernel_size=3,padding=1)\n",
        "        self.e12 = nn.Conv3d(64, 64, kernel_size=3,padding=1)\n",
        "        self.pool1 = nn.MaxPool3d(kernel_size=2, stride=2) #64x64x64\n",
        "\n",
        "        self.e21 = nn.Conv3d(64, 128, kernel_size=3,padding=1)\n",
        "        self.e22 = nn.Conv3d(128, 128, kernel_size=3,padding=1)\n",
        "        self.pool2 = nn.MaxPool3d(kernel_size=2, stride=2) #32x32x128\n",
        "\n",
        "        self.e31 = nn.Conv3d(128, 256, kernel_size=3,padding=1)\n",
        "        self.e32 = nn.Conv3d(256, 256, kernel_size=3,padding=1)\n",
        "        self.pool3 = nn.MaxPool3d(kernel_size=2, stride=2) #16x16x256\n",
        "\n",
        "        self.e41 = nn.Conv3d(256, 512, kernel_size=3,padding=1)\n",
        "        self.e42 = nn.Conv3d(512, 512, kernel_size=3,padding=1)\n",
        "\n",
        "        self.upconv2 = nn.ConvTranspose3d(512,256,kernel_size=2,stride=2) #\n",
        "        self.d21 = nn.Conv3d(512,256,kernel_size=3,padding=1)\n",
        "        self.d22 = nn.Conv3d(256,256,kernel_size=3,padding=1)\n",
        "\n",
        "        self.upconv3 = nn.ConvTranspose3d(256,128,kernel_size=2,stride=2)\n",
        "        self.d31 = nn.Conv3d(256,128,kernel_size=3,padding=1)\n",
        "        self.d32 = nn.Conv3d(128,128,kernel_size=3,padding=1)\n",
        "\n",
        "        self.upconv4 = nn.ConvTranspose3d(128,64,kernel_size=2,stride=2)\n",
        "        self.d41 = nn.Conv3d(128,64,kernel_size=3,padding=1)\n",
        "        self.d42 = nn.Conv3d(64,64,kernel_size=3,padding=1)\n",
        "\n",
        "        self.outconv = nn.Conv3d(64, n_class, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Encoder\n",
        "        xe11 = F.relu(self.e11(x))\n",
        "        xe12 = F.relu(self.e12(xe11))\n",
        "        xp1 = self.pool1(xe12)\n",
        "\n",
        "        xe21 = F.relu(self.e21(xp1))\n",
        "        xe22 = F.relu(self.e22(xe21))\n",
        "        xp2 = self.pool2(xe22)\n",
        "\n",
        "\n",
        "        xe31 = F.relu(self.e31(xp2))\n",
        "        xe32 = F.relu(self.e32(xe31))\n",
        "\n",
        "        xp3 = self.pool3(xe32)\n",
        "\n",
        "        xe41 = F.relu(self.e41(xp3))\n",
        "        xe42 = F.relu(self.e42(xe41))\n",
        "\n",
        "        # Decoder\n",
        "        xup2 = self.upconv2(xe42)\n",
        "        xcat2 = torch.cat([xup2, xe32], dim=1)\n",
        "\n",
        "\n",
        "        xup31 = F.relu(self.d21(xcat2))\n",
        "        xup32 = F.relu(self.d22(xup31))\n",
        "        xup3 = self.upconv3(xup32)\n",
        "        xcat3 = torch.cat([xup3, xe22], dim=1)\n",
        "\n",
        "        xup41 = F.relu(self.d31(xcat3))\n",
        "        xup42 = F.relu(self.d32(xup41))\n",
        "\n",
        "        xup4 = self.upconv4(xup42)\n",
        "        xcat4 = torch.cat([xup4, xe12], dim=1)\n",
        "        xup51 = F.relu(self.d41(xcat4))\n",
        "        xup52 = F.relu(self.d42(xup51))\n",
        "\n",
        "        out = self.outconv(xup52)\n",
        "\n",
        "        output = out\n",
        "\n",
        "        return output\n",
        "\n",
        "print(\"Defined Unet\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aUE3unVCfDCR",
        "outputId": "7a304068-55ce-4812-c44d-95f8829e9af8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Defined Unet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Setting up hyper parameters, from exercise week 6\n",
        "loss_fn =  nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "7xzJxGxVfMf3"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating dataset\n",
        "class SOCDataset(Dataset):\n",
        "    def __init__(self, root_dir):\n",
        "        self.root_dir = root_dir\n",
        "        self.image_folder = os.path.join(root_dir, 'data/')\n",
        "        self.label_folder = os.path.join(root_dir, 'labels/')\n",
        "        self.image_filenames = sorted([f for f in os.listdir(self.image_folder) if f.endswith('.tiff')])\n",
        "        self.label_filenames = sorted([f for f in os.listdir(self.label_folder) if f.endswith('.tif')])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_filenames)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "      img_name = os.path.join(self.image_folder, self.image_filenames[idx])\n",
        "\n",
        "      number1=img_name[-8:-5] #Making sure image and label match\n",
        "      label_name=os.path.join(self.label_folder,'slice__'+str(number1)+'.tif')\n",
        "\n",
        "      image = cv2.imread(img_name, cv2.IMREAD_GRAYSCALE)\n",
        "      label = cv2.imread(label_name, cv2.IMREAD_GRAYSCALE)\n",
        "      image=torch.from_numpy(np.array(image))\n",
        "      label=torch.from_numpy(np.array(label))\n",
        "\n",
        "      return image, label\n"
      ],
      "metadata": {
        "id": "ajvzgy6tfPiu"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SOC_dataset = SOCDataset(root_dir='drive/My Drive//AI data/') #change path if running on the HPC\n",
        "\n",
        "print('loaded data')\n",
        "\n",
        "images=[]\n",
        "labels=[]\n",
        "for i in range(len(SOC_dataset)):\n",
        "  image,label=SOC_dataset[i]\n",
        "\n",
        "  images.append(image)\n",
        "  labels.append(label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B64bQe9Ffpau",
        "outputId": "26038462-0d3c-462b-9f15-ae7631659cdd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loaded data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def split_cube(volume,cube_size):\n",
        "\n",
        "  vol_split=volume.unfold(2, cube_size, cube_size).unfold(1, cube_size, cube_size).unfold(0, cube_size, cube_size)\n",
        "\n",
        "  vol_split=vol_split.reshape([vol_split.size(0)**3,cube_size,cube_size,cube_size])\n",
        "  return vol_split"
      ],
      "metadata": {
        "id": "EVi-CK8HfXRB"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#creating large volumes\n",
        "im_vol=torch.stack(images)\n",
        "labels_vol=torch.stack(labels)\n",
        "\n",
        "#Creating sub volumes\n",
        "im_vol=split_cube(im_vol,64)\n",
        "label_vol=split_cube(labels_vol,64)"
      ],
      "metadata": {
        "id": "FirCyVsNfxrk"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchio as tio\n",
        "from re import I\n",
        "\n",
        "#Splitting data in images and labelled images\n",
        "#This is implemented with the torchio workflow\n",
        "elements = []\n",
        "for i in range(im_vol.size(0)):\n",
        "    element = tio.Subject(\n",
        "        image_sub=tio.ScalarImage(tensor=im_vol.unsqueeze(0)[:,i,:,:]),\n",
        "        label_sub=tio.LabelMap(tensor=label_vol.unsqueeze(0)[:,i,:,:]),\n",
        "    )\n",
        "    elements.append(element)\n",
        "dataset = tio.SubjectsDataset(elements)"
      ],
      "metadata": {
        "id": "zvH5rQKmfxo0"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Adding normalization of pixel intensities,\n",
        "transforms = (\n",
        "    tio.ZNormalization(masking_method=tio.ZNormalization.mean)\n",
        ")\n",
        "\n",
        "transform = transforms"
      ],
      "metadata": {
        "id": "uK5qfme5fxil"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "339vDMpEfxRx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Splitting in training, validation and test data\n",
        "\n",
        "#splitting ratios\n",
        "training_size=0.7\n",
        "val_split=0.5\n",
        "\n",
        "#Find number of images in train, val and test\n",
        "train_number = int(training_size * len(dataset))\n",
        "val_number = len(dataset) - train_number\n",
        "test_number = val_number*val_split\n",
        "\n",
        "#splitting of training and validation set\n",
        "train_val = train_number, val_number\n",
        "train_images, val_images = torch.utils.data.random_split(elements, train_val)\n",
        "\n",
        "val_test = int(val_number*val_split), int(val_number*val_split)+1\n",
        "test_images,val_images = torch.utils.data.random_split(val_images,val_test)\n",
        "\n",
        "#Creating datasets with pixel normalization\n",
        "train_set = tio.SubjectsDataset(\n",
        "    train_images, transform=transform)\n",
        "\n",
        "val_set = tio.SubjectsDataset(\n",
        "    val_images, transform=transform)\n",
        "\n",
        "test_set = tio.SubjectsDataset(\n",
        "    test_images, transform=transform)\n",
        "\n",
        "print('Training set:', len(train_set), 'subjects')\n",
        "print('Validation set:', len(val_set), 'subjects')\n",
        "print('Test set:', len(test_set), 'subjects')\n"
      ],
      "metadata": {
        "id": "e_z-izFygGvH",
        "outputId": "b2bc742e-fc78-4630-ef99-39173b17135e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set: 240 subjects\n",
            "Validation set: 52 subjects\n",
            "Test set: 51 subjects\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import multiprocessing\n",
        "num_workers = 4 #adapted to the HPC\n",
        "\n",
        "#Train batch size of 16, validation batch size of 32\n",
        "training_batch_size = 16\n",
        "validation_batch_size = 2 * training_batch_size\n",
        "\n",
        "#Splitting in training, test and validation\n",
        "training_loader = torch.utils.data.DataLoader(\n",
        "    train_set,\n",
        "    batch_size=training_batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=num_workers,\n",
        ")\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "    val_set,\n",
        "    batch_size=validation_batch_size,\n",
        "    num_workers=num_workers,\n",
        ")\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    test_set,\n",
        "    batch_size=validation_batch_size,\n",
        "    num_workers=num_workers,\n",
        ")"
      ],
      "metadata": {
        "id": "DMbiXjdAgGsg",
        "outputId": "4ff1a5e4-5319-4690-c32a-c15bdbc297d1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torchmetrics\n"
      ],
      "metadata": {
        "id": "3qQ7Y0ZvgGo5",
        "outputId": "0456fe4a-6a75-4cef-e66f-c152a098680c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-1.2.1-py3-none-any.whl (806 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m806.1/806.1 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.23.5)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (23.2)\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.1.0+cu121)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
            "  Downloading lightning_utilities-0.10.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (67.7.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.13.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.1->torchmetrics) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.1->torchmetrics) (1.3.0)\n",
            "Installing collected packages: lightning-utilities, torchmetrics\n",
            "Successfully installed lightning-utilities-0.10.0 torchmetrics-1.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.load('drive/My Drive//Models/3dunet.pth')\n"
      ],
      "metadata": {
        "id": "apN9Rp4tVNUt"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing accuracy metrics\n",
        "from torchmetrics.classification import JaccardIndex\n",
        "from torchmetrics.functional.classification import dice\n",
        "from torchmetrics.classification import MulticlassAccuracy"
      ],
      "metadata": {
        "id": "sGXwoL8IMyDf"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.utils import make_grid\n",
        "\n",
        "test_accuracies_dice=0\n",
        "test_accuracies_jaccard=0\n",
        "test_accuracies_pixel=0\n",
        "l_test=0\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "jaccard=JaccardIndex(task=\"multiclass\", num_classes=3).to(device) #jaccard\n",
        "accuracy=MulticlassAccuracy(num_classes=3).to(device) #pixel wise\n",
        "\n",
        "\n",
        "\n",
        "for subjects_batch in test_loader:\n",
        "  inputs = subjects_batch['image_sub'][tio.DATA].to(device)\n",
        "  targets = subjects_batch['label_sub'][tio.DATA].to(device)\n",
        "  output = model(inputs)\n",
        "\n",
        "  un_target=targets.unique()\n",
        "  targets[targets==un_target[0]]=0\n",
        "  targets[targets==un_target[1]]=1\n",
        "  targets[targets==un_target[2]]=2\n",
        "\n",
        "  targets = targets.to(torch.int64) [:,0,:,:,:]\n",
        "\n",
        "  #Computing test accuracies\n",
        "  predicted = torch.argmax(softmax(output,dim=1),dim=1)\n",
        "  predicted=predicted.to(torch.int64)\n",
        "  for i in range(predicted.size(0)):\n",
        "    test_accuracies_dice+=dice(predicted[i,:,:,:],targets[i,:,:,:])\n",
        "    test_accuracies_jaccard+=jaccard(predicted[i,:,:,:],targets[i,:,:,:])\n",
        "    test_accuracies_pixel+=accuracy(predicted[i,:,:,:],targets[i,:,:,:])\n",
        "  l_test+=predicted.size(0) #save size of batchsize\n",
        "\n",
        "#Average test accuracy\n",
        "test_dice=(test_accuracies_dice/l_test).cpu()\n",
        "test_jaccard=(test_accuracies_jaccard/l_test).cpu()\n",
        "test_pixel=(test_accuracies_pixel/l_test).cpu()\n",
        "\n",
        "print(\"Finished test loader\")\n",
        "\n"
      ],
      "metadata": {
        "id": "iyqfxhKIgS8Q",
        "outputId": "98a96b67-8ed3-4b63-f0e2-55c44fd4df13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-39d2d926b7b5>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubjects_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image_sub'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDATA\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubjects_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label_sub'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDATA\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m   \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m   \u001b[0mun_target\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-08f56d3118d4>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;31m# Encoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mxe11\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0me11\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0mxe12\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0me12\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxe11\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mxp1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxe12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mrelu\u001b[0;34m(input, inplace)\u001b[0m\n\u001b[1;32m   1469\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1470\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1471\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1472\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 2.00 GiB. GPU 0 has a total capacty of 14.75 GiB of which 55.06 MiB is free. Process 3504 has 14.69 GiB memory in use. Of the allocated memory 13.59 GiB is allocated by PyTorch, and 1003.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"test_accuracies_dice: {test_dice}\")\n",
        "print(f\"test_accuracies_jaccard: {test_jaccard}\")\n",
        "print(f\"test_accuracies_pixel: {test_pixel}\")"
      ],
      "metadata": {
        "id": "fHdQQLdKsttr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label1=output[0,0,:,:,:].cpu().detach().numpy()\n",
        "label2=output[0,1,:,:,:].cpu().detach().numpy()\n",
        "label3=output[0,2,:,:,:].cpu().detach().numpy()\n",
        "\n",
        "predicted=predicted.cpu().detach().numpy() [0,:,:,:]\n",
        "\n",
        "params = {'legend.fontsize': 'x-large',\n",
        "          'figure.figsize': (5, 5),\n",
        "         'axes.labelsize': 'x-large',\n",
        "         'axes.titlesize':'x-large',\n",
        "         'xtick.labelsize':'x-large',\n",
        "         'ytick.labelsize':'x-large'}\n",
        "pylab.rcParams.update(params)\n",
        "\n",
        "x, y, z = np.meshgrid(np.arange(label1.shape[0]),np.arange(label1.shape[1]),np.arange(label1.shape[2]), indexing='ij')\n",
        "fig = plt.figure(dpi=200)\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "im=ax.scatter(x, y, z, c=predicted.flatten(), cmap='viridis', marker='o')\n",
        "ax.set_xlabel('Number of pixels [#]')\n",
        "fig.colorbar(im,ticks=[0,1,2],label='Label number', pad = 0.1, fraction = 0.05)\n",
        "plt.title('Prediction')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "plt.savefig('Prediction.png')\n"
      ],
      "metadata": {
        "id": "Sdv5EuAeizM2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "params = {'legend.fontsize': 'x-large',\n",
        "          'figure.figsize': (5, 5),\n",
        "         'axes.labelsize': 'x-large',\n",
        "         'axes.titlesize':'x-large',\n",
        "         'xtick.labelsize':'x-large',\n",
        "         'ytick.labelsize':'x-large'}\n",
        "pylab.rcParams.update(params)\n",
        "\n",
        "targets=targets.cpu().detach().numpy() [0,:,:,:]\n",
        "x, y, z = np.meshgrid(np.arange(label1.shape[0]),np.arange(label1.shape[1]),np.arange(label1.shape[2]), indexing='ij')\n",
        "fig = plt.figure(dpi=200)\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "im2=ax.scatter(x, y, z, c=targets.flatten(), cmap='viridis', marker='o')\n",
        "ax.set_xlabel('Number of pixels [#]')\n",
        "fig.colorbar(im2,ticks=[0,1,2],label='Label number', pad = 0.1, fraction = 0.05)\n",
        "plt.title('Target')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "plt.savefig('Target.png')\n",
        "\n",
        "params = {'legend.fontsize': 'x-large',\n",
        "          'figure.figsize': (5, 5),\n",
        "         'axes.labelsize': 'x-large',\n",
        "         'axes.titlesize':'x-large',\n",
        "         'xtick.labelsize':'x-large',\n",
        "         'ytick.labelsize':'x-large'}\n",
        "pylab.rcParams.update(params)\n",
        "\n",
        "#Difference plot, example with one image\n",
        "fig = plt.figure(dpi=200)\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "im3=ax.scatter(x, y, z, c=np.abs(targets.flatten()-predicted.flatten()), cmap='viridis', marker='o')\n",
        "ax.set_xlabel('Number of pixels [#]')\n",
        "fig.colorbar(im3,ticks=[0,1,2],label='Difference in label number', pad = 0.1, fraction = 0.05)\n",
        "plt.title('Absolute difference in labels')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "plt.savefig('Diff')\n",
        "\n",
        "\n",
        "#Splitting volume cube in slices\n",
        "plt.figure(dpi=200)\n",
        "plt.imshow(np.abs(targets[0,:,32,:]-predicted[:,32,:]))\n",
        "plt.colorbar()\n",
        "plt.title('Horizontal slice, layer 32')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "plt.savefig('Horizontal_slice_32')\n",
        "\n",
        "plt.figure(dpi=200)\n",
        "plt.imshow(np.abs(targets[0,:,:,15]-predicted[:,:,15]))\n",
        "plt.colorbar()\n",
        "plt.title('Vertical slice, layer 15')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "plt.savefig('Horizontal_slice_15')\n",
        "\n",
        "plt.figure(dpi=200)\n",
        "plt.imshow(np.abs(targets[0,:,45,:]-predicted[:,45,:]))\n",
        "plt.colorbar()\n",
        "plt.title('Horizontal slice, layer 45')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "plt.savefig('Horizontal_slice_45')\n",
        "\n",
        "plt.figure(dpi=200)\n",
        "plt.imshow(np.abs(targets[0,:,:,34]-predicted[:,:,34]))\n",
        "plt.colorbar()\n",
        "plt.title('Vertical slice, layer 34')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "plt.savefig('Horizontal_slice_34')"
      ],
      "metadata": {
        "id": "B60xZMRrgS0f"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}